{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393c92e2-0396-4797-8de5-a6578bd6ea66",
   "metadata": {},
   "source": [
    "# Обработка текста на примере предсказание тематики новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc5c30-4c37-4dfd-8e0b-e29bd1cbc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ad896-fded-4a71-9e8f-8429a27f3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'MODELS':'models',\n",
    "    'LR':os.path.join('models','LogisticRegression'),\n",
    "    'FASTTEXT':os.path.join('models','fasttext'),\n",
    "    'DATA':'data',\n",
    "    'TRAIN':os.path.join('data','train'),\n",
    "    'TEST':os.path.join('data','test')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c536b93-dcd1-47ef-8247-2e3068608581",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'nt':  \n",
    "            print(path)\n",
    "            !mkdir {path}\n",
    "        elif os.name == 'posix':\n",
    "            !mkdir {path}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f676ca-38f6-41ef-937d-a7b441ae197e",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48eb19-be90-4fcc-a283-8614bdc4c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title','text','topic','tags'])\n",
    "for df_text in pd.read_csv(os.path.join(paths['DATA'],'lenta-ru-news.csv'), chunksize=1000):\n",
    "    df_text = df_text[['title','text','topic','tags']]\n",
    "    df = pd.concat([df,df_text])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05084a6d-21a3-4e60-ad41-35b6a0a5bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.tags=='Украина','topic'] = 'Украина'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43e912-fa9f-480a-ba31-8eed9de187fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df[[\"text\",'topic']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31745f09-fce9-4c09-b10e-3b1358e3b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'topic!=\"Крым\"&topic!=\"Сочи\"&topic!=\"МедНовости\"&topic!=\"ЧМ-2014\"&topic!=\"Оружие\"&topic!=\"Библиотека\" \\\n",
    "                &topic!=\"Легпром\"&topic!=\"Культпросвет \"&topic!=\"69-я параллель\"'\n",
    "df_text = df_text.query(query)\n",
    "df_text.topic = df_text.topic.apply(lambda x: x.replace(' ','_'))\n",
    "df_text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf311f7-a6b3-409f-b217-5b4e48edad5d",
   "metadata": {},
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9bdb2-a525-41fb-80b5-a01e7c526188",
   "metadata": {},
   "source": [
    "Обрабатывать данные будем двумя способами.\n",
    "1. с помощью метода simple_preproces библиотеки gensim \n",
    "2. с помощью написанного класса CleanText, используя simple преобразования\n",
    "3. с помощью написанного класса CleanText, применяя удаления стопслов и стеминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284187cb-b173-4277-9db7-d64045e9843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6669c99-d424-405b-a15a-d6c91572800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class CleanText(str):\n",
    "    def __init__(self,text=''):\n",
    "        self.options = defaultdict(bool)\n",
    "    def __call__(self,text=''):\n",
    "        if self.options['full_transform']:\n",
    "            text = self.remove_whit_re(text)\n",
    "            text = self.remove_punctuation(text)\n",
    "            text = self.remove_stopwords(text)\n",
    "            text = self.apply_stemming(text)        \n",
    "            return text\n",
    "        text = self.remove_whit_re(text)\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.remove_one_char(text)\n",
    "        return text              \n",
    "    \n",
    "    \n",
    "    def set_options(self,\n",
    "                    simple=False, \n",
    "                    full_transform=False, \n",
    "                    ):\n",
    "        self.options['simple']=simple\n",
    "        self.options['full_transform']=full_transform         \n",
    "    \n",
    "    \n",
    "    def remove_one_char(self, text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        return ' '.join([word for word in text.split(' ') if len(word)>1 or len(word)>18])\n",
    "    \n",
    "    \n",
    "    def remove_inicial(self,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        return re.sub(\"\\.*\\s[A-ZА-Я]\\.\",\"\",text)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def remove_whit_re(self,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        return re.sub(\"[A-ZА-Я]\\.|http[://A-Za-zА-Яа-я\\.]*|www.*[A-Za-z]+\\.[a-zA-Z]+\",\"\",text)\n",
    "    \n",
    "    \n",
    "    def lower(self,text:str):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        return text.lower()\n",
    "    \n",
    "   \n",
    "    def remove_punctuation(self,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        whitespace = string.whitespace.replace(' ','')\n",
    "        punctuations = string.punctuation+'«»'\n",
    "        digits = string.digits\n",
    "        schars=whitespace+punctuations+digits  \n",
    "        text = text.replace('-',' ')\n",
    "        return \"\".join([char for char in text.lower() \\\n",
    "                        if char not in schars])\n",
    "    \n",
    "    \n",
    "    def remove_stopwords(self,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        stemmer = SnowballStemmer('russian')\n",
    "        stop_words = stopwords.words('russian')\n",
    "        return \" \".join([stemmer.stem(word) for word in text.split(' ') if word not in stop_words])\n",
    "   \n",
    "\n",
    "  \n",
    "    def apply_stemming(self,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        stemmer = SnowballStemmer('russian')\n",
    "        return \" \".join(stemmer.stem(word) for word in text.split(' '))\n",
    "    \n",
    "    \n",
    "    def transform(self,lst_good_words:list,text:str=''):\n",
    "        if self:\n",
    "            text = self+' '+text\n",
    "        return \" \".join([words for words in text.split(' ') if words in lst_good_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654ed0a-802c-4385-ab9d-2066693c7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for text in tqdm(df_text.text.values):\n",
    "    row.append(' '.join(simple_preprocess(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c44f2-4964-4657-b198-3c586fadca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1 = []\n",
    "cleaner = CleanText()\n",
    "for text in tqdm(df_text.text.values):\n",
    "    row_1.append(cleaner(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872eed2-1e68-4b52-a223-f273ac931356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim = pd.DataFrame(list(zip(row,df_text.topic.values)), columns=['text','topic']).dropna()\n",
    "df_cleaner = pd.DataFrame(list(zip(row_1,df_text.topic.values)), columns=['text','topic']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1658a1-010d-4683-98e3-07f7463583a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaner.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18742f-8784-4a11-abbe-ab673b8143f6",
   "metadata": {},
   "source": [
    "### Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecb5ed-0655-4335-8872-366f00378e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim.to_csv(os.path.join(paths['DATA'],'gensim.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55416154-2fac-4388-967b-b8d4d61f7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaner.to_csv(os.path.join(paths['DATA'],'cleaner.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f405056-7718-4606-acc6-ff697f365fab",
   "metadata": {},
   "source": [
    "В итоге написанный класс в среднем на 20 процентов быстрее предобробатывает русский текст, и также имеет возможноть удалять url адреса"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-text",
   "language": "python",
   "name": "venv-text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
