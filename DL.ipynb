{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28159c93-4c4a-4003-a801-3b1c69bca968",
   "metadata": {},
   "source": [
    "## Решение на основе нейронных сетей (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18633d03-d915-4437-88f6-04c41b1d96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c78ec13-3370-496c-899a-0158ff0c1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'MODELS':'models',\n",
    "    'LR':os.path.join('models','LogisticRegression'),\n",
    "    'FASTTEXT':os.path.join('models','fasttext'),\n",
    "    'VECTOR':os.path.join('models','vector'),\n",
    "    'DATA':'data',\n",
    "    'TRAIN':os.path.join('data','train'),\n",
    "    'TEST':os.path.join('data','test'),\n",
    "    'UTILS':'utils',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90902a13-f4f3-483c-a09d-f701d822dd53",
   "metadata": {},
   "source": [
    "### Загрузка предобработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db395410-e6d5-44a3-9790-340a7f547b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim = pd.read_csv(os.path.join(paths['DATA'],'gensim.csv'), index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319a0b14-ca05-4a56-86a4-a690b81cdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaner = pd.read_csv(os.path.join(paths['DATA'],'cleaner.csv'), index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b87153-e3b6-4562-b8a6-589b9890c538",
   "metadata": {},
   "source": [
    "### Формирование тестовой и обучающей выборки с учетом несбалансированности классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12fcd67-cd25-4f21-b6b0-2d8bd36edf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3bc85-2745-4225-a206-2519fb90df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gensim, X_test_gensim, y_train_gensim, y_test_gensim = train_test_split(df_gensim.text, \n",
    "                                                                                df_gensim.topic,  \n",
    "                                                                                test_size=0.2, \n",
    "                                                                                stratify=df_gensim.topic,\n",
    "                                                                                random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b39d557-5684-421a-a36e-d1591408fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(df_cleaner.text,\n",
    "                                                                            df_cleaner.topic,\n",
    "                                                                            test_size=0.2, \n",
    "                                                                            stratify=df_cleaner.topic, \n",
    "                                                                            random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465f5ada-5c3b-4189-84d6-d2625a3a548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 592874/592874 [00:31<00:00, 19055.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "result = []\n",
    "for text in tqdm(X_train_clean.values):\n",
    "    result.append(text.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241b49e5-2ada-46bb-b0cc-a5a1074bfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_len = len(np.unique(y_train_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971c551-320e-47c1-89e9-d6bfaac92914",
   "metadata": {},
   "source": [
    "#### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4681b0-5514-4e56-a5c4-fcdb2be1e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585d8d50-1f34-4aeb-b292-834392e69b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "russuia_w2v = api.load('word2vec-ruscorpora-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6644cc-eeec-4267-bbe2-86c1c9c9638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "def get_vocab(words:list, vectors:list)->dict:\n",
    "    dct = defaultdict(str)\n",
    "    print(len(words),len(vectors))\n",
    "    for word, vector in zip(words,vectors):\n",
    "        key = re.sub('_[A-Z]*','',word)\n",
    "        dct[key] = vector\n",
    "    return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c022224e-7b79-483c-b292-e134836e02ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184973 184973\n"
     ]
    }
   ],
   "source": [
    "dct_words = get_vocab(russuia_w2v.index_to_key,russuia_w2v.vectors)\n",
    "dct_idx = {name:idx for idx, name  in enumerate(dct_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c54dcb-d700-4f0a-a00a-fc0913f21d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b0688a-3e43-46d1-93d8-78e19bac659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(paths['UTILS'],'dct_words.bin'),'wb') as file:\n",
    "    pickle.dump(dct_words,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "746115cc-0bfb-472b-b5c9-5c28ff05e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef9dfe3-abb9-4e0e-8dc1-333bbe3f625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text: str, dct_idx:dict)->np.array:\n",
    "    result = []\n",
    "    for word in text.split():\n",
    "        value = dct_idx.get(word, None)\n",
    "        if value is not None:\n",
    "            result.append(value)\n",
    "    return np.asarray(result)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5b3289-8714-4d7e-be32-281a7713965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_sentence(text:str, dct_vocab:dict):\n",
    "    result = []\n",
    "    for word in text.split()[-100:]:\n",
    "        try:\n",
    "            vector = dct_vocab[word]\n",
    "            if not isinstance(vector,str):\n",
    "                result.append(vector)\n",
    "        except KeyError :\n",
    "            result.append([])\n",
    "            \n",
    "    return np.asarray(result, dtype=object).flatten()\n",
    "    # return np.array(result).flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3585615-0374-4d86-a3be-1c193e903e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183533it [00:00, 195170.64it/s]\n"
     ]
    }
   ],
   "source": [
    "embending_matrix = np.zeros(shape=(len(dct_words),300))\n",
    "for idx, word in tqdm(enumerate(dct_words)):\n",
    "    embed_vector = dct_words.get(word,None)\n",
    "    if embed_vector is not None:\n",
    "        embending_matrix[idx] = embed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12a47b68-8405-43cd-8586-75de83d67a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = {name:i for i, name in enumerate(np.unique(y_train_clean))}\n",
    "y_train_2 = {str(idx):name for name, idx in y_train_1.items()}\n",
    "y_train = np.asarray([y_train_1[item] for item in y_train_clean])\n",
    "y_test = np.asarray([y_train_1[item] for item in y_test_clean])\n",
    "y_train = keras.utils.to_categorical(y_train).astype(np.int16)\n",
    "y_test = keras.utils.to_categorical(y_test).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbadc88b-b870-47ec-90d6-1fce3ca5b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 592874/592874 [01:57<00:00, 5034.94it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for text in tqdm(X_train_clean):\n",
    "    vector_sentence = tokenizer(text, dct_idx)\n",
    "    X_train.append(vector_sentence)\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "450d17e2-78b6-4ee5-a2cf-2fb81ab7ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 148219/148219 [00:10<00:00, 14745.96it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for text in tqdm(X_test_clean):\n",
    "    vector_sentence = tokenizer(text, dct_idx)\n",
    "    X_test.append(vector_sentence)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a6654f4-c71d-4281-822b-734a9a3ca791",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(dct_words)\n",
    "VECTOR_SIZE =  russuia_w2v.vector_size\n",
    "MAX_LENGTH = 100\n",
    "OUTPUT_LEN = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b3be744-5dc8-45bf-bff7-d6845e5cb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layers = Embedding(input_dim=VOCAB_SIZE,\n",
    "                             output_dim=VECTOR_SIZE,\n",
    "                             input_length=MAX_LENGTH,\n",
    "                             embeddings_initializer=keras.initializers.Constant(embending_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0711c86-55e7-4f70-af1a-79a06e0f7f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592874, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f05f39a0-d5f1-4ade-b4cd-e167ded2c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGRU = keras.models.Sequential()\n",
    "modelGRU.add(embedding_layers)\n",
    "modelGRU.add(keras.layers.GRU(1024))\n",
    "modelGRU.add(keras.layers.Dense(OUTPUT_LEN, activation='softmax'))\n",
    "modelGRU.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=keras.metrics.CategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "541f908d-edbd-4877-93e6-b43e9d06fa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 300)          55059900  \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 1024)              4073472   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                15375     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,148,747\n",
      "Trainable params: 59,148,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4cebff1-169f-424e-8c81-e0135e630fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_point = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(paths['MODELS'],'Word_vect','GRU_2.hdf5'),\n",
    "    monitor='val_categorical_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    ")\n",
    "erly_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    min_delta=0.01,\n",
    "    patience=2,\n",
    "    mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822da93-aadd-42eb-a9d5-c376dc97a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGRU.fit(\n",
    "    x=X_train,\n",
    "    y=y_train, \n",
    "    epochs=5, \n",
    "    batch_size=64,\n",
    "    validation_data=(X_test,y_test),\n",
    "    callbacks=[ch_point,erly_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d379d44-d32b-4a19-a84a-f946a1a23192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4632/4632 [==============================] - 110s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = modelGRU.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93c71c4-fcdb-4520-8a37-83059162d9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 5, ..., 9, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "276a9dde-88fe-440d-9520-023a5dad0124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 5, ..., 7, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "257ce769-53d0-4703-87d0-49d306a761ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "735229c2-9fca-4844-8d46-94dad6e04cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.asarray([y_train_2[str(idx)] for idx in np.argmax(y_test, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c10cc75d-3461-432d-b3e1-ad9b30f08f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.asarray([y_train_2[str(idx)] for idx in np.argmax(predict, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67018890-560a-43bd-8618-38d30133be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           Бизнес       0.57      0.46      0.51      1480\n",
      "      Бывший_СССР       0.78      0.72      0.75      7094\n",
      "              Дом       0.84      0.75      0.79      4347\n",
      "         Из_жизни       0.75      0.47      0.58      5521\n",
      "   Интернет_и_СМИ       0.77      0.69      0.73      8933\n",
      "         Культура       0.85      0.89      0.87     10759\n",
      "              Мир       0.81      0.82      0.81     27324\n",
      "  Наука_и_техника       0.81      0.85      0.83     10627\n",
      "      Путешествия       0.66      0.63      0.65      1281\n",
      "           Россия       0.77      0.84      0.81     32088\n",
      "Силовые_структуры       0.68      0.50      0.58      3919\n",
      "            Спорт       0.96      0.96      0.96     12883\n",
      "          Украина       0.85      0.83      0.84      4504\n",
      "         Ценности       0.89      0.84      0.86      1553\n",
      "        Экономика       0.80      0.87      0.83     15906\n",
      "\n",
      "         accuracy                           0.81    148219\n",
      "        macro avg       0.79      0.74      0.76    148219\n",
      "     weighted avg       0.81      0.81      0.81    148219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410272b8-0d17-4cbb-b385-0e4bbc91d0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-text",
   "language": "python",
   "name": "venv-text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
